{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b8d4ffbe-66ff-4b8e-9a68-7951fae95d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "import unidecode\n",
    "import yaml\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6494d9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load & configure tokeninzer\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('./tokenizers/gpt2_2k')\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]', 'mask_token': '[MASK]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e0069e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file for the model\n",
    "with open(f'./configs/lstm.yaml', 'r') as in_file:\n",
    "    cfg = yaml.load(in_file, Loader=yaml.FullLoader)\n",
    "hparams = cfg['model']['architecture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6cd3c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean & normlize text\n",
    "def clean(text):\n",
    "    t = text.lower()\n",
    "    t = t.replace('\\\\n', ' ').replace('\\\\t', ' ').replace('\\t', ' ').replace('. com', '.com')\n",
    "    t = re.sub(r'https?:\\/\\/[a-z.\\/A-Z\\d]*', ' ', t)\n",
    "    t = re.sub(r\"\\ [A-Za-z]*\\.com\", ' ', t)\n",
    "    t = re.sub(r\"@\\S+\", '', t)\n",
    "    t = t.replace('@', '')\n",
    "    t = unidecode.unidecode(t)\n",
    "    t = t.replace('#', '_')\n",
    "    \n",
    "    to_replace = [\"&quot;\", ':&lt;', ':&gt;', '&amp;', '-&lt;', '-&gt;', '=&lt;', '=&gt;', 's&lt;', 's&gt;']\n",
    "    for x in to_replace:\n",
    "        t = t.replace(x, '')\n",
    "    pattern = re.compile(r\"([A-Za-z])\\1{1,}\", re.DOTALL)\n",
    "    t = pattern.sub(r\"\\1\\1\", t)\n",
    "    \n",
    "    pattern = re.compile(r\"([\\s.,\\/#!$%^&*?;:{}=_`()+-])\\1{1,}\")\n",
    "    t = pattern.sub(r'\\1', t)\n",
    "    t = re.sub(' {2,}', '', t)\n",
    "    t = t.lower()\n",
    "    t = t.strip()\n",
    "    t = t.rstrip()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "4aa26edb-51ec-4fe6-80c4-6e1d4afb1042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitt = \"@Orange I looooooove the new Livebox, it's so pretty #Livebox6\"\n",
    "twitt = \"@Bosch my freaking battery catch fire last night rosting my cat #RIPfluffy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2184b824-0489-4622-aa7c-5cda6ea83387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my freaking battery catch fire last night rosting my cat _ripfluffy'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(twitt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ea4c2bf3-1542-44cc-ad14-5220b7bec47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(twitt)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c9d8a62b-69b4-4b37-a0b3-7a1150ef5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model weights\n",
    "model_weights = torch.load('./models/lstm_128.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678cd680-5456-4994-b042-5b421ebad5e3",
   "metadata": {},
   "source": [
    "## Embeddings Layer\n",
    "A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
    "\n",
    "This module is used to store tokens embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c94c2887-8273-4254-89fa-a82cbc20baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEmbeddings:\n",
    "    def __init__(self, model: Dict):\n",
    "        self.embs = dict(zip(range(2000), model['encoder.embs.weight'].numpy()))\n",
    "        \n",
    "    def forward(self, x: List[int]):\n",
    "        return np.array([self.embs[idx] for idx in x])\n",
    "\n",
    "    def __call__(self, x: List[int]):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "dd25ee1e-65c4-4b63-927a-c1535618cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = NpEmbeddings(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "bb07baa9-7c99-4553-b6bd-273936c7d39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00664131, -0.00703674, -0.01127713, ...,  0.00683154,\n",
       "         0.00050304, -0.01573904],\n",
       "       [-0.00697829,  0.01343679, -0.0078092 , ...,  0.00431453,\n",
       "        -0.00435441, -0.00223201],\n",
       "       [ 0.06620484,  0.16069634, -0.03993553, ..., -0.10422891,\n",
       "        -0.05582594,  0.02631515],\n",
       "       ...,\n",
       "       [ 0.06088695, -0.0635412 , -0.08631796, ...,  0.01144394,\n",
       "         0.12519038,  0.05046234],\n",
       "       [ 0.2222735 , -0.13870618,  0.13226719, ...,  0.10218486,\n",
       "        -0.04203468, -0.00406977],\n",
       "       [ 0.0276247 ,  0.03676317, -0.0945969 , ..., -0.01917078,\n",
       "        -0.09409595,  0.19517466]], dtype=float32)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = embs(input_ids)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ae775c-794f-4962-a5f8-0d7f9af8a6b7",
   "metadata": {},
   "source": [
    "## Layer Normalization\n",
    "Layer Normalization normalizes the data with respect to the last dimension of the tensor. The formula is \n",
    "\n",
    "$y = \\frac{x-E[x]}{\\sqrt{Var[x]+1e-4}}*\\gamma+\\beta$\n",
    "\n",
    "The mean and the standard deviation are calculated over the last dimension. The parameters $\\gamma$ and $\\beta$ are learn during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "271b4f22-9c74-44a1-bcd2-dc7bf77e0aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpLayerNorm:\n",
    "    def __init__(self, hparams: Dict, model: Dict):\n",
    "        self.hparams = hparams\n",
    "        self.eps = 1e-5\n",
    "        self.gamma = torch.load('./models/lstm_128.pt')['encoder.embs_norm.weight'].numpy()\n",
    "        self.beta = torch.load('./models/lstm_128.pt')['encoder.embs_norm.bias'].numpy()\n",
    "        \n",
    "    def forward(self, x: np.array):\n",
    "        assert x.shape[-1] == self.hparams['hidden_dim']\n",
    "        assert len(x.shape) == 2\n",
    "        r = np.zeros(x.shape)\n",
    "        for i in range(x.shape[0]):\n",
    "            r[i] = (x[i] - np.mean(x[i])) / (np.sqrt(np.var(x[i]) + self.eps)) * self.gamma + self.beta\n",
    "        return r\n",
    "    \n",
    "    def __call__(self, x: np.array):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ff55fd9b-d29d-4d1a-a4b8-362717f52dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "npLN = NpLayerNorm(hparams, model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d287ba40-0c5b-4a0a-a638-1e9bbdbcd032",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = npLN(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d3458e-5467-42b4-afe2-2a05d8f559db",
   "metadata": {},
   "source": [
    "# LSTM Layer\n",
    "Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.\n",
    "\n",
    "For each element in the input sequence, the following function is computed:\n",
    "\n",
    "![](img/lstm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c1d5ad4d-2e2d-41e6-9795-29fc2873cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: np.array):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class NpLSTM:\n",
    "    def __init__(self, hparams: Dict, model: Dict):\n",
    "        self.hparams = hparams\n",
    "        self.W_ii, self.W_if, self.W_ig, self.W_io = model['encoder.lstm.weight_ih_l0'].split(self.hparams['hidden_dim'])\n",
    "        self.W_hi, self.W_hf, self.W_hg, self.W_ho = model['encoder.lstm.weight_hh_l0'].split(self.hparams['hidden_dim'])\n",
    "        self.b_ii, self.b_if, self.b_ig, self.b_io = model['encoder.lstm.bias_ih_l0'].split(self.hparams['hidden_dim'])\n",
    "        self.b_hi, self.b_hf, self.b_hg, self.b_ho = model['encoder.lstm.bias_hh_l0'].split(self.hparams['hidden_dim'])\n",
    "        \n",
    "        self.W_ii, self.W_if, self.W_ig, self.W_io = self.W_ii.numpy(), self.W_if.numpy(), self.W_ig.numpy(), self.W_io.numpy()\n",
    "        self.W_hi, self.W_hf, self.W_hg, self.W_ho = self.W_hi.numpy(), self.W_hf.numpy(), self.W_hg.numpy(), self.W_ho.numpy()\n",
    "        self.b_ii, self.b_if, self.b_ig, self.b_io = self.b_ii.numpy(), self.b_if.numpy(), self.b_ig.numpy(), self.b_io.numpy()\n",
    "        self.b_hi, self.b_hf, self.b_hg, self.b_ho = self.b_hi.numpy(), self.b_hf.numpy(), self.b_hg.numpy(), self.b_ho.numpy()\n",
    "        \n",
    "    def lstm_cell(self, x_t, h_tm1, c_tm1):\n",
    "        i_t = sigmoid(\n",
    "            np.dot(self.W_ii, x_t) + self.b_ii + np.dot(self.W_hi, h_tm1) + self.b_hi\n",
    "        )\n",
    "        f_t = sigmoid(\n",
    "            np.dot(self.W_if, x_t) + self.b_if + np.dot(self.W_hf, h_tm1) + self.b_hf\n",
    "        )\n",
    "        g_t = np.tanh(\n",
    "            np.dot(self.W_ig, x_t) + self.b_ig + np.dot(self.W_hg, h_tm1) + self.b_hg\n",
    "        )\n",
    "        o_t = sigmoid(\n",
    "            np.dot(self.W_io, x_t) + self.b_io + np.dot(self.W_ho, h_tm1) + self.b_ho\n",
    "        )\n",
    "\n",
    "        c_t = f_t * c_tm1 + i_t * g_t\n",
    "        h_t = o_t * np.tanh(c_t)\n",
    "\n",
    "        return o_t, h_t, c_t\n",
    "\n",
    "    def forward(self, x: np.array):\n",
    "        assert len(x.shape) == 2\n",
    "        assert x.shape[1] == self.hparams['hidden_dim']\n",
    "        \n",
    "        x_t, h_t, c_t = None, np.zeros(self.hparams['hidden_dim']), np.zeros(self.hparams['hidden_dim'])\n",
    "        for i in range(x.shape[0]):\n",
    "            x_t = x[i]\n",
    "            _, h_t, c_t = self.lstm_cell(x_t, h_t, c_t)\n",
    "\n",
    "        return h_t\n",
    "    \n",
    "    def __call__(self, x: np.array):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "37e154fa-d5a7-40c8-a33e-9bbb05da98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nplstm = NpLSTM(hparams, model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "3ee9f992-61a2-484a-a54d-7146c8aa8ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nplstm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ebda6d-4fb3-401b-bd71-b6ad51e50da0",
   "metadata": {},
   "source": [
    "## Classification Head\n",
    "The classification head is simply two dense layer with a tanh in between. Both layers have biases.\n",
    "\n",
    "The head output the logit, to get the probability don't forget to apply a sigmoid to the logit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "057146f8-f47f-49d6-846e-49658981b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpClassificationHead:\n",
    "    def __init__(self, hparams: Dict, model: Dict):\n",
    "        self.hparams = hparams\n",
    "        self.dense1_w = model['fc.dense1.weight'].numpy().T\n",
    "        self.dense1_b = model['fc.dense1.bias'].numpy()\n",
    "        \n",
    "        self.dense2_w = model['fc.dense2.weight'].numpy().T\n",
    "        self.dense2_b = model['fc.dense2.bias'].numpy()\n",
    "    \n",
    "    def forward(self, x: np.array):\n",
    "        assert len(x.shape) == 1\n",
    "        assert x.shape[0] == self.hparams['hidden_dim']\n",
    "        \n",
    "        x = np.dot(x, self.dense1_w) + self.dense1_b\n",
    "        x = np.tanh(x)\n",
    "        x = np.dot(x, self.dense2_w) + self.dense2_b\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def __call__(self, x: np.array):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ea5d6eaa-0be3-407d-9369-4ee4621d7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "npfc = NpClassificationHead(hparams, model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "1e39a3a0-0633-4deb-8945-b23a71528b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = npfc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "112acfd8-27aa-4940-b3e3-c1f00bdaf645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1304966])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = sigmoid(x)\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ac5be8-4e5d-4ec1-9fdd-4bca22c5bbac",
   "metadata": {},
   "source": [
    "## Putting it all Together\n",
    "By putting all layers together gives us the classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9fe681bd-4e63-47b2-bfdb-c95c028b40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpClassifier:\n",
    "    def __init__(self, hparams: Dict, model: Dict):\n",
    "        self.hparams = hparams\n",
    "        self.embs = NpEmbeddings(model)\n",
    "        self.lnorm = NpLayerNorm(hparams, model)\n",
    "        self.lstm = NpLSTM(hparams, model)\n",
    "        self.fc = NpClassificationHead(hparams, model)\n",
    "        \n",
    "    def forward(self, input_ids: List[int]):\n",
    "        x = self.embs(input_ids)\n",
    "        x = self.lnorm(x)\n",
    "        x = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        x = sigmoid(x)\n",
    "        return float(x)\n",
    "    \n",
    "    def __call__(self, input_ids: List[int]):\n",
    "        return self.forward(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7f6ee589",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NpClassifier(hparams, model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "5fdfc909-0ad8-40a9-bbf7-08094a17f644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13049660450326692"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267113c8-adc9-4f54-9d96-452164f60293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "57fe836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model on the data.\n",
    "# in:\n",
    "#    data: list of twitts\n",
    "# out:\n",
    "#    res: a list of tuples (twitt, pred)\n",
    "\n",
    "def predict(data: List[str]):\n",
    "    data_clean = [clean(t) for t in data]\n",
    "    preds = [classifier(tokenizer(t)['input_ids']) for t in data_clean]\n",
    "    preds = [float(x) for x in preds]\n",
    "    return list(zip(data, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "37d02700",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"I just created my first LaTeX file from scratch. That didn't work out very well. (See @amandabittner , it's a great time waster)\",\n",
    "    \"AHH YES LOL IMA TELL MY HUBBY TO GO GET ME SUM MCDONALDS =]\",\n",
    "    \"RT @shrop: Awesome JQuery reference book for Coda! http://www.macpeeps.com/coda/ #webdesign\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "03f02f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"I just created my first LaTeX file from scratch. That didn't work out very well. (See @amandabittner , it's a great time waster)\",\n",
       "  0.25448374732423096),\n",
       " ('AHH YES LOL IMA TELL MY HUBBY TO GO GET ME SUM MCDONALDS =]',\n",
       "  0.8471391608879367),\n",
       " ('RT @shrop: Awesome JQuery reference book for Coda! http://www.macpeeps.com/coda/ #webdesign',\n",
       "  0.9531386291444308)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e6878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
